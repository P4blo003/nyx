# ==========================================================================================
# Author: Pablo González García.
# Created: 20/01/2025
# Last edited: 20/01/2025
#
# Defines the Triton Inference Server available for the AI Service.
# Each server entry contains connection information required to send inference requests.
# ==========================================================================================


# ==============================
# MAPPING
# ==============================

servers:
  # ONNX Triton Server used for embedding and classification tasks.
  triton-onnx:
    host: triton-onnx                         # Backend server host.
    http_port: 8000                           # HTTP endpoint port.
    grpc_port: 8001                           # gRPC endpoint port.

  # VLLM Triton Server used for text-generation tasks.
  triton-vllm:
    host: triton-vllm                         # Backend server host.
    http_port: 8000                           # HTTP endpoint port.
    grpc_port: 8001                           # gRPC endpoint port.