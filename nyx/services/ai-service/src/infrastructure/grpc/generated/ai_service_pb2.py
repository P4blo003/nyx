# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: ai-service.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'ai-service.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x10\x61i-service.proto\x12\rai_service.v1\x1a\x1bgoogle/protobuf/empty.proto\x1a\x1fgoogle/protobuf/timestamp.proto\"4\n\x0fModelIdentifier\x12\x10\n\x08model_id\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"\xa8\x01\n\x0bModelStatus\x12\x10\n\x08model_id\x18\x01 \x01(\t\x12/\n\x05state\x18\x02 \x01(\x0e\x32 .ai_service.v1.ModelStatus.State\x12\x0f\n\x07message\x18\x03 \x01(\t\"E\n\x05State\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0b\n\x07LOADING\x10\x01\x12\t\n\x05READY\x10\x02\x12\x0c\n\x08UNLOADED\x10\x03\x12\t\n\x05\x45RROR\x10\x04\"#\n\x11ListModelsRequest\x12\x0e\n\x06\x66ilter\x18\x01 \x01(\t\"B\n\x12ListModelsResponse\x12,\n\x06models\x18\x01 \x03(\x0b\x32\x1c.ai_service.v1.ModelMetadata\"2\n\rModelMetadata\x12\x10\n\x08model_id\x18\x01 \x01(\t\x12\x0f\n\x07version\x18\x02 \x01(\t\"@\n\x10InferenceRequest\x12,\n\ndata_input\x18\x01 \x03(\x0b\x32\x18.ai_service.v1.DataInput\"=\n\tDataInput\x12\x0e\n\x04text\x18\x01 \x01(\tH\x00\x12\x15\n\x0b\x62inary_data\x18\x02 \x01(\x0cH\x00\x42\t\n\x07payload\"A\n\x11InferenceResponse\x12,\n\tembedding\x18\x01 \x03(\x0b\x32\x19.ai_service.v1.DataOutput\"\\\n\nDataOutput\x12\x0e\n\x04text\x18\x01 \x01(\tH\x00\x12\x33\n\tembedding\x18\x02 \x01(\x0b\x32\x1e.ai_service.v1.EmbeddingVectorH\x00\x42\t\n\x07payload\"!\n\x0f\x45mbeddingVector\x12\x0e\n\x06values\x18\x01 \x03(\x02\x32\xa0\x03\n\tAIService\x12R\n\x0blist_models\x12 .ai_service.v1.ListModelsRequest\x1a!.ai_service.v1.ListModelsResponse\x12H\n\nload_model\x12\x1e.ai_service.v1.ModelIdentifier\x1a\x1a.ai_service.v1.ModelStatus\x12J\n\x0cunload_model\x12\x1e.ai_service.v1.ModelIdentifier\x1a\x1a.ai_service.v1.ModelStatus\x12O\n\nmake_infer\x12\x1f.ai_service.v1.InferenceRequest\x1a .ai_service.v1.InferenceResponse\x12X\n\x11make_infer_stream\x12\x1f.ai_service.v1.InferenceRequest\x1a .ai_service.v1.InferenceResponse0\x01\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'ai_service_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_MODELIDENTIFIER']._serialized_start=97
  _globals['_MODELIDENTIFIER']._serialized_end=149
  _globals['_MODELSTATUS']._serialized_start=152
  _globals['_MODELSTATUS']._serialized_end=320
  _globals['_MODELSTATUS_STATE']._serialized_start=251
  _globals['_MODELSTATUS_STATE']._serialized_end=320
  _globals['_LISTMODELSREQUEST']._serialized_start=322
  _globals['_LISTMODELSREQUEST']._serialized_end=357
  _globals['_LISTMODELSRESPONSE']._serialized_start=359
  _globals['_LISTMODELSRESPONSE']._serialized_end=425
  _globals['_MODELMETADATA']._serialized_start=427
  _globals['_MODELMETADATA']._serialized_end=477
  _globals['_INFERENCEREQUEST']._serialized_start=479
  _globals['_INFERENCEREQUEST']._serialized_end=543
  _globals['_DATAINPUT']._serialized_start=545
  _globals['_DATAINPUT']._serialized_end=606
  _globals['_INFERENCERESPONSE']._serialized_start=608
  _globals['_INFERENCERESPONSE']._serialized_end=673
  _globals['_DATAOUTPUT']._serialized_start=675
  _globals['_DATAOUTPUT']._serialized_end=767
  _globals['_EMBEDDINGVECTOR']._serialized_start=769
  _globals['_EMBEDDINGVECTOR']._serialized_end=802
  _globals['_AISERVICE']._serialized_start=805
  _globals['_AISERVICE']._serialized_end=1221
# @@protoc_insertion_point(module_scope)
