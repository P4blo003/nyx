# ==========================================================================================
# Author: Pablo González García.
# Created: 09/02/2026
# Last edited: 09/02/2026
# ==========================================================================================


# ==============================
# ENDPOINTS
# ==============================

# This section defines the endpoints for the Triton Inference Server instances.
endpoints:

  triton-onnx:
    # Host and port for the Triton Inference Server.
    host: "triton-onnx"
    # gRPC port for triton inference.
    port: 8001

# This section defines the tasks that the AI Service will handle, mapping them to the corresponding endpoints and models.
tasks:

  embedding-inference:
    # The endpoint to which this task is assigned.
    endpoint: triton-onnx
    # The model name to be used for this task.
    model_name: "bge_m3_ensemble"