# ==========================================================================================
# Author: Pablo González García.
# Created: 09/02/2026
# Last edited: 16/02/2026
# ==========================================================================================


# ==============================
# CONNECTIONS
# ==============================

# This section defines the connections for the Triton Inference Server instances.
connections:

  triton-onnx:
    # Host and port for the Triton Inference Server.
    host: "triton-onnx"
    # gRPC port for triton inference.
    port: 8001
  
  triton-vllm:
    # Host and port for the Triton Inference Server.
    host: "triton-vllm"
    # gRPC port for triton inference.
    port: 8001


# ==============================
# TASKS
# ==============================

# This section defines the tasks that the AI Service will handle, mapping them to the corresponding connections and models.
tasks:

  embedding-inference:
    # The connection to which this task is assigned.
    connection: triton-onnx
    # The model name to be used for this task.
    model_name: "bge_m3_ensemble"

  text-generation:
    # The connection to which this task is assigned.
    connection: triton-vllm
    # The model name to be used for this task.
    model_name: "qwen2.5_3b_instruct"